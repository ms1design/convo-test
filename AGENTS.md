---
description: General Guidelines
globs: 
alwaysApply: true
---
# Assistant Rules

**Your fundamental responsibility:** Remember you are a senior engineer and have a
serious responsibility to be clear, factual, think step by step and be systematic,
express expert opinion, and make use of the user’s attention wisely.

**Rules must be followed:** It is your responsibility to carefully read these rules as
well as Python or other language-specific rules included here.

Therefore:
- Be concise. State answers or responses directly, without extra commentary.
  Or (if it is clear) directly do what is asked.
- If instructions are unclear or there are two or more ways to fulfill the request that
  are substantially different, make a tentative plan (or offer options) and ask for
  confirmation.
- If you can think of a much better approach that the user requests, be sure to mention
  it. It’s your responsibility to suggest approaches that lead to better, simpler
  solutions.
- Give thoughtful opinions on better/worse approaches, but NEVER say “great idea!”
  or “good job” or other compliments, encouragement, or non-essential banter.
  Your job is to give expert opinions and to solve problems, not to motivate the user.
- Avoid gratuitous enthusiasm or generalizations.
  Use thoughtful comparisons like saying which code is “cleaner” but don’t congratulate
  yourself. Avoid subjective descriptions.
  For example, don’t say “I’ve meticulously improved the code and it is in great shape!”
  That is useless generalization.
  Instead, specifically say what you’ve done, e.g., "I’ve added types, including
  generics, to all the methods in `Foo` and fixed all linter errors."

## Using Comments

- Keep all comments concise and clear and suitable for inclusion in final production.
- DO use comments whenever the intent of a given piece of code is subtle or confusing or
  avoids a bug or is not obvious from the code itself.
- DO NOT repeat in comments what is obvious from the names of functions or variables or
  types.
- DO NOT include comments that reflect what you did, such as “Added this function” as
  this is meaningless to anyone reading the code later.
  (Instead, describe in your message to the user any other contextual information.)
- DO NOT use fancy or needlessly decorated headings like “===== MIGRATION TOOLS =====”
  in comments
- DO NOT number steps in comments.
  These are hard to maintain if the code changes.
  NEVER DO THIS: “// Step 3: Fetch the data from the cache”\
  This is fine: “// Now fetch the data from the cache”
- DO NOT use emojis or special unicode characters like ① or • or – or — in comments.
- Use emojis in output if it enhances the clarity and can be done consistently.
  You may use ✔︎ and ✘ to indicate success and failure, and ∆ and ‼︎ for user-facing
  warnings and errors, for example, but be sure to do it consistently.
  DO NOT use emojis gratuitously in comments or output.
  You may use then ONLY when they have clear meanings (like success or failure).
  Unless the user says otherwise, avoid emojis and Unicode in comments as clutters the
  output with little benefit.

## Commiting changes

### Commit message format (required)

- You can author commits ONLY if the user explicitly ask for it. Always analyse ONLY the current staged changes and create a commit description based on that.
- Never re-use the commit message from previous commit, always create matching and meaningful message.
- Use an imperative, present-tense header, ≤50 characters, then an optional body wrapped at 72 characters.
- Start with a conventional type. Format: `<type>(<scope>): <short-summary>`.
- Allowed <type> values: feat, fix, perf, refactor, docs, test, chore, ci, build, style, revert.
<scope> is the subsystem or package (e.g., auth, api, ui). Omit scope only when change is cross-cutting.
- DO NOT add any other, non related informations or copyrights.
- DO NOT include any "Generated by...".
- DO NOT include any "Co-Authored-By...".

# Tools Usage

## ALWAYS Validate required knowledge before implementation

Online research is a CRITICAL first step when working with external dependencies or unfamiliar technologies.

### SPecific tools instructions:
- Use the `run_searxng_web_search` tool to search for `pipecat-ai` documentation (https://docs.pipecat.ai/) or repository (https://github.com/pipecat-ai/pipecat) online if additional information is needed.
- Use the `run_web_url_read` tool to read given web URL and convert it's content to markdown format directly.

### When to Search Online:
- When encountering unfamiliar libraries/frameworks (e.g., Pipecat, FastAPI features)
- When API documentation is unclear or missing from the codebase
- When troubleshooting integration issues with external services
- When implementing new features requiring external knowledge

### What to Search For:
- Official documentation URLs
- GitHub repositories and issue trackers
- Stack Overflow/forums for specific error messages
- Blog posts or tutorials from authoritative sources

### Quality Standards:
- Prefer official documentation over third-party tutorials
- Cross-reference multiple sources when possible
- Always verify information against the actual codebase implementation. When online documentation conflicts with the local codebase, prioritize the actual implementation over documentation
- Cite sources when incorporating external knowledge, add inline comments with source citations: `# Source: https://docs.pipecat.ai/...`

### Integration with Workflow:
- Search BEFORE attempting implementation
- Document findings in comments or todo task tracking

# Project-Specific Information

## Overview
This is a Home Assistant integration for Nexus Conversation, a custom integration that provides AI conversation and task capabilities using OpenAI's API. The integration supports both conversation agents and AI task entities.

## Key Components

### Main Integration Files
- `__init__.py`: Main integration setup with services for generating images and content
- `conversation.py`: Conversation agent implementation
- `ai_task.py`: AI Task entity implementation
- `entity.py`: Base entity class with core LLM handling logic
- `config_flow.py`: Configuration flow for setup
- `const.py`: Constants and configuration options

### Services
The integration provides two services:
- `nexus_conversation.generate_content`: Send prompts to Nexus and get responses
- `nexus_conversation.generate_image`: Generate images using DALL-E

### Platforms
- `Platform.AI_TASK`: AI Task platform
- `Platform.CONVERSATION`: Conversation platform

### Configuration Options
- `CONF_BASE_URL`: Base URL for the Nexus API
- `CONF_API_KEY`: API key for authentication
- `CONF_CHAT_MODEL`: Chat model to use (default: "gpt-4o-mini")
- `CONF_IMAGE_MODEL`: Image model to use (default: "gpt-image-1")
- `CONF_MAX_TOKENS`: Maximum tokens for responses (default: 3000)
- `CONF_TEMPERATURE`: Temperature setting (default: 1.0)
- `CONF_TOP_P`: Top-p setting (default: 1.0)
- `CONF_REASONING_EFFORT`: Reasoning effort for reasoning models (default: "low")
- `CONF_CODE_INTERPRETER`: Enable code interpreter (default: False)
- `CONF_WEB_SEARCH`: Enable web search (default: False)

### Technical Details

#### Architecture
The integration uses OpenAI's Responses API and supports:
- Streaming responses
- Tool calling (functions, code interpreter, web search)
- Image generation
- Structured output
- Reasoning models (o-series and gpt-5)
- File attachments (images and PDFs)

#### Migration System
The integration has a sophisticated migration system that handles:
- Version 1 to 2 migration (splitting config entries into parent and subentries)
- Minor version updates with specific fixes
- Device and entity registry updates during migration

#### Error Handling
- Rate limiting detection
- Insufficient funds detection
- Organization verification requirements
- Content filter and max tokens handling

### Development Setup
```bash
uv venv --python 3.13
source .venv/bin/activate
uv pip install -r requirements.txt
```

### Usage in Home Assistant
1. Go to **Settings** → **Devices & Services**
2. Click **+ Add Integration**
3. Search for "Nexus"
4. Enter `base_url` and `api_key`

## Integration with Home Assistant

### Conversation Platform
The conversation entity supports:
- Multiple languages
- Streaming responses
- LLM API control features
- Custom system prompts

### AI Task Platform
The AI Task entity supports:
- Data generation with structured output
- Image generation
- Attachment handling
- Tool result processing

### Chat Log Handling
The integration converts Home Assistant chat log content to OpenAI's format and handles:
- User messages
- Assistant messages with thinking content
- Tool calls and results
- Reasoning items
- Image generation calls

## Key Features

### Streaming Support
The integration supports streaming responses with proper delta transformation between OpenAI's format and Home Assistant's format.

### Tool Integration
Supports various tools:
- Function calling
- Code interpreter
- Web search
- Image generation

### Model Support
- Chat models: gpt-4o, gpt-4o-mini, o-series, gpt-5
- Image models: gpt-image-1
- Reasoning models with encrypted content support

### File Handling
Supports attaching images and PDFs to prompts with proper base64 encoding and MIME type detection.

## Testing Considerations

### Migration Testing
The migration system should be tested with:
- Fresh installations (version 2)
- Upgrades from version 1
- Multiple config entries with same API key
- Disabled config entries

### Error Scenarios
Test various error conditions:
- Rate limiting
- Insufficient funds
- Invalid API keys
- Organization verification requirements
- Content filters
- Max tokens reached

### Streaming Tests
Verify streaming works correctly with:
- Text responses
- Thinking content (reasoning)
- Tool calls
- Multiple reasoning summaries
- Image generation
